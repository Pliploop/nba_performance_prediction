{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import seaborn as sns   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/nba_logreg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1340"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>...</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brandon Ingram</td>\n",
       "      <td>36</td>\n",
       "      <td>27.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>34.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>69.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andrew Harrison</td>\n",
       "      <td>35</td>\n",
       "      <td>26.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JaKarr Sampson</td>\n",
       "      <td>74</td>\n",
       "      <td>15.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>42.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malik Sealy</td>\n",
       "      <td>58</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>42.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>68.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Geiger</td>\n",
       "      <td>48</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9</td>\n",
       "      <td>67.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name  GP   MIN  PTS  FGM  FGA   FG%  3P Made  3PA   3P%  ...  \\\n",
       "0   Brandon Ingram  36  27.4  7.4  2.6  7.6  34.7      0.5  2.1  25.0  ...   \n",
       "1  Andrew Harrison  35  26.9  7.2  2.0  6.7  29.6      0.7  2.8  23.5  ...   \n",
       "2   JaKarr Sampson  74  15.3  5.2  2.0  4.7  42.2      0.4  1.7  24.4  ...   \n",
       "3      Malik Sealy  58  11.6  5.7  2.3  5.5  42.6      0.1  0.5  22.6  ...   \n",
       "4      Matt Geiger  48  11.5  4.5  1.6  3.0  52.4      0.0  0.1   0.0  ...   \n",
       "\n",
       "   FTA   FT%  OREB  DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "0  2.3  69.9   0.7   3.4  4.1  1.9  0.4  0.4  1.3          0.0  \n",
       "1  3.4  76.5   0.5   2.0  2.4  3.7  1.1  0.5  1.6          0.0  \n",
       "2  1.3  67.0   0.5   1.7  2.2  1.0  0.5  0.3  1.0          0.0  \n",
       "3  1.3  68.9   1.0   0.9  1.9  0.8  0.6  0.1  1.0          1.0  \n",
       "4  1.9  67.4   1.0   1.5  2.5  0.3  0.3  0.4  0.8          1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'GP', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3P Made', '3PA',\n",
       "       '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK',\n",
       "       'TOV', 'TARGET_5Yrs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name            0\n",
       "GP              0\n",
       "MIN             0\n",
       "PTS             0\n",
       "FGM             0\n",
       "FGA             0\n",
       "FG%             0\n",
       "3P Made         0\n",
       "3PA             0\n",
       "3P%            11\n",
       "FTM             0\n",
       "FTA             0\n",
       "FT%             0\n",
       "OREB            0\n",
       "DREB            0\n",
       "REB             0\n",
       "AST             0\n",
       "STL             0\n",
       "BLK             0\n",
       "TOV             0\n",
       "TARGET_5Yrs     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(figsize = (5,5))\n",
    "sns.barplot(data = (df.TARGET_5Yrs.value_counts()/df.TARGET_5Yrs.value_counts().sum()).reset_index(), x = 'index', y = 'TARGET_5Yrs', palette= 'spring', edgecolor = 'k', linewidth = 1, alpha = .5)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.test import NBAevaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = NBAevaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading and cleaning dataset\n",
      "splitting into test and train set\n",
      "scaling train data and applying on test data\n",
      "fitting classifiers on train set\n",
      "fitting: KNNC\n",
      "fitting: SVC\n",
      "fitting: SVCGamma\n",
      "fitting: RFC\n",
      "fitting: MLPC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting: XGBC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "5760 fits failed out of a total of 11520.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5760 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 533, in fit\n",
      "    raise ValueError(\n",
      "ValueError: criterion='mae' is not supported. Use criterion='friedman_mse' or 'squared_error' instead, as trees should use a squared error criterion in Gradient Boosting.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.62396313 0.62396313 0.63870968 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "5760 fits failed out of a total of 11520.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5760 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 533, in fit\n",
      "    raise ValueError(\n",
      "ValueError: criterion='mae' is not supported. Use criterion='friedman_mse' or 'squared_error' instead, as trees should use a squared error criterion in Gradient Boosting.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.61935484 0.61935484 0.62211982 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "5760 fits failed out of a total of 11520.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5760 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 533, in fit\n",
      "    raise ValueError(\n",
      "ValueError: criterion='mae' is not supported. Use criterion='friedman_mse' or 'squared_error' instead, as trees should use a squared error criterion in Gradient Boosting.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.62211982 0.62211982 0.62488479 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "5760 fits failed out of a total of 11520.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5760 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 533, in fit\n",
      "    raise ValueError(\n",
      "ValueError: criterion='mae' is not supported. Use criterion='friedman_mse' or 'squared_error' instead, as trees should use a squared error criterion in Gradient Boosting.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.62488479 0.62488479 0.63778802 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "5760 fits failed out of a total of 11520.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5760 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 533, in fit\n",
      "    raise ValueError(\n",
      "ValueError: criterion='mae' is not supported. Use criterion='friedman_mse' or 'squared_error' instead, as trees should use a squared error criterion in Gradient Boosting.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.62580645 0.62580645 0.62764977 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "5760 fits failed out of a total of 11520.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5760 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 533, in fit\n",
      "    raise ValueError(\n",
      "ValueError: criterion='mae' is not supported. Use criterion='friedman_mse' or 'squared_error' instead, as trees should use a squared error criterion in Gradient Boosting.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.62119816 0.62119816 0.63778802 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "5760 fits failed out of a total of 11520.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5760 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 533, in fit\n",
      "    raise ValueError(\n",
      "ValueError: criterion='mae' is not supported. Use criterion='friedman_mse' or 'squared_error' instead, as trees should use a squared error criterion in Gradient Boosting.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.62707056 0.62707056 0.63443961 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "5760 fits failed out of a total of 11520.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5760 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 533, in fit\n",
      "    raise ValueError(\n",
      "ValueError: criterion='mae' is not supported. Use criterion='friedman_mse' or 'squared_error' instead, as trees should use a squared error criterion in Gradient Boosting.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.62707056 0.62707056 0.6307572  ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "5760 fits failed out of a total of 11520.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5760 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 533, in fit\n",
      "    raise ValueError(\n",
      "ValueError: criterion='mae' is not supported. Use criterion='friedman_mse' or 'squared_error' instead, as trees should use a squared error criterion in Gradient Boosting.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.62246649 0.62246649 0.63444806 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "5760 fits failed out of a total of 11520.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5760 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 533, in fit\n",
      "    raise ValueError(\n",
      "ValueError: criterion='mae' is not supported. Use criterion='friedman_mse' or 'squared_error' instead, as trees should use a squared error criterion in Gradient Boosting.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.61325836 0.61325836 0.6335264  ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting: logreg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "150 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.62396313        nan 0.62396313        nan 0.62396313\n",
      "        nan 0.62396313        nan 0.62396313        nan 0.62764977\n",
      "        nan 0.63225806        nan 0.64976959        nan 0.66635945\n",
      "        nan 0.68663594        nan 0.69585253        nan 0.69861751\n",
      "        nan 0.70138249        nan 0.70599078        nan 0.70599078\n",
      "        nan 0.70599078        nan 0.71059908        nan 0.70967742\n",
      "        nan 0.70691244        nan 0.70691244        nan 0.70414747\n",
      "        nan 0.70414747        nan 0.70230415        nan 0.69769585\n",
      "        nan 0.69677419        nan 0.69493088        nan 0.69677419\n",
      "        nan 0.69493088        nan 0.69493088        nan 0.69493088]\n",
      "  warnings.warn(\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "150 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.61935484        nan 0.61935484        nan 0.61935484\n",
      "        nan 0.61935484        nan 0.61935484        nan 0.62211982\n",
      "        nan 0.62949309        nan 0.64700461        nan 0.66820276\n",
      "        nan 0.69032258        nan 0.6921659         nan 0.6921659\n",
      "        nan 0.69677419        nan 0.69953917        nan 0.70599078\n",
      "        nan 0.7078341         nan 0.70414747        nan 0.70046083\n",
      "        nan 0.70046083        nan 0.70230415        nan 0.70322581\n",
      "        nan 0.69953917        nan 0.70046083        nan 0.69493088\n",
      "        nan 0.69493088        nan 0.69308756        nan 0.6921659\n",
      "        nan 0.69493088        nan 0.69308756        nan 0.69124424]\n",
      "  warnings.warn(\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "150 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.62211982        nan 0.62211982        nan 0.62211982\n",
      "        nan 0.62211982        nan 0.62211982        nan 0.62304147\n",
      "        nan 0.62949309        nan 0.64331797        nan 0.66543779\n",
      "        nan 0.6875576         nan 0.69124424        nan 0.69585253\n",
      "        nan 0.70138249        nan 0.70414747        nan 0.70230415\n",
      "        nan 0.70138249        nan 0.70230415        nan 0.70046083\n",
      "        nan 0.69953917        nan 0.69400922        nan 0.6921659\n",
      "        nan 0.68847926        nan 0.68847926        nan 0.68663594\n",
      "        nan 0.68663594        nan 0.68571429        nan 0.68663594\n",
      "        nan 0.68663594        nan 0.68663594        nan 0.68479263]\n",
      "  warnings.warn(\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "150 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.62488479        nan 0.62488479        nan 0.62488479\n",
      "        nan 0.62488479        nan 0.62488479        nan 0.62857143\n",
      "        nan 0.63870968        nan 0.65714286        nan 0.67926267\n",
      "        nan 0.69677419        nan 0.70322581        nan 0.70599078\n",
      "        nan 0.71336406        nan 0.71705069        nan 0.71981567\n",
      "        nan 0.71797235        nan 0.72073733        nan 0.71981567\n",
      "        nan 0.71520737        nan 0.71705069        nan 0.71612903\n",
      "        nan 0.71520737        nan 0.70967742        nan 0.70875576\n",
      "        nan 0.70691244        nan 0.70967742        nan 0.70875576\n",
      "        nan 0.71059908        nan 0.71152074        nan 0.7124424 ]\n",
      "  warnings.warn(\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "150 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.62580645        nan 0.62580645        nan 0.62580645\n",
      "        nan 0.62580645        nan 0.62580645        nan 0.62764977\n",
      "        nan 0.62949309        nan 0.640553          nan 0.66635945\n",
      "        nan 0.68847926        nan 0.69769585        nan 0.70138249\n",
      "        nan 0.70046083        nan 0.70414747        nan 0.70230415\n",
      "        nan 0.70414747        nan 0.70322581        nan 0.70322581\n",
      "        nan 0.70506912        nan 0.70506912        nan 0.70322581\n",
      "        nan 0.70599078        nan 0.70414747        nan 0.69861751\n",
      "        nan 0.69493088        nan 0.69585253        nan 0.69585253\n",
      "        nan 0.69677419        nan 0.69585253        nan 0.69677419]\n",
      "  warnings.warn(\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "150 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.62119816        nan 0.62119816        nan 0.62119816\n",
      "        nan 0.62119816        nan 0.62304147        nan 0.62580645\n",
      "        nan 0.63502304        nan 0.65345622        nan 0.67926267\n",
      "        nan 0.69400922        nan 0.69953917        nan 0.70875576\n",
      "        nan 0.71059908        nan 0.71152074        nan 0.71059908\n",
      "        nan 0.71152074        nan 0.7124424         nan 0.7124424\n",
      "        nan 0.70967742        nan 0.70875576        nan 0.71059908\n",
      "        nan 0.70875576        nan 0.70875576        nan 0.70599078\n",
      "        nan 0.70691244        nan 0.70599078        nan 0.70599078\n",
      "        nan 0.70599078        nan 0.7078341         nan 0.70875576]\n",
      "  warnings.warn(\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "150 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.62707056        nan 0.62707056        nan 0.62707056\n",
      "        nan 0.62707056        nan 0.62707056        nan 0.63075297\n",
      "        nan 0.63443538        nan 0.64826026        nan 0.67125523\n",
      "        nan 0.69978438        nan 0.69885427        nan 0.69978438\n",
      "        nan 0.70347525        nan 0.71084006        nan 0.71453093\n",
      "        nan 0.7145267         nan 0.71360927        nan 0.7145267\n",
      "        nan 0.71176172        nan 0.70807931        nan 0.70624022\n",
      "        nan 0.70347525        nan 0.70255782        nan 0.70163193\n",
      "        nan 0.70071027        nan 0.69887118        nan 0.69886695\n",
      "        nan 0.69610197        nan 0.69518454        nan 0.69518877]\n",
      "  warnings.warn(\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "150 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.62707056        nan 0.62707056        nan 0.62707056\n",
      "        nan 0.62707056        nan 0.62707056        nan 0.63075297\n",
      "        nan 0.63351372        nan 0.64917769        nan 0.66757705\n",
      "        nan 0.69150636        nan 0.70163616        nan 0.70254936\n",
      "        nan 0.70716611        nan 0.70993531        nan 0.71822179\n",
      "        nan 0.71822179        nan 0.71730013        nan 0.71453938\n",
      "        nan 0.71177863        nan 0.71270029        nan 0.71085275\n",
      "        nan 0.7090052         nan 0.71084006        nan 0.70992263\n",
      "        nan 0.70807931        nan 0.706236          nan 0.70623177\n",
      "        nan 0.70531434        nan 0.70807086        nan 0.70899674]\n",
      "  warnings.warn(\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "150 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.62246649        nan 0.62246649        nan 0.62246649\n",
      "        nan 0.62246649        nan 0.62246649        nan 0.62430558\n",
      "        nan 0.63258783        nan 0.66021646        nan 0.68321989\n",
      "        nan 0.69151482        nan 0.69243225        nan 0.6998182\n",
      "        nan 0.70534393        nan 0.70995645        nan 0.711804\n",
      "        nan 0.71456475        nan 0.71364309        nan 0.71916459\n",
      "        nan 0.71640384        nan 0.71364309        nan 0.71363886\n",
      "        nan 0.71087811        nan 0.71456475        nan 0.71179977\n",
      "        nan 0.70719148        nan 0.70718302        nan 0.70994377\n",
      "        nan 0.70718302        nan 0.70810468        nan 0.70441804]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoring best classifiers on test set\n",
      "KNNC:\n",
      "confusion matrix: \n",
      " [[38 16]\n",
      " [23 57]]\n",
      "recall : 0.7125 - precision : 0.7808219178082192 - accuracy : 0.7089552238805971\n",
      "SVC:\n",
      "confusion matrix: \n",
      " [[29 25]\n",
      " [14 66]]\n",
      "recall : 0.825 - precision : 0.7252747252747253 - accuracy : 0.7089552238805971\n",
      "SVCGamma:\n",
      "confusion matrix: \n",
      " [[31 23]\n",
      " [15 65]]\n",
      "recall : 0.8125 - precision : 0.7386363636363636 - accuracy : 0.7164179104477612\n",
      "RFC:\n",
      "confusion matrix: \n",
      " [[29 25]\n",
      " [15 65]]\n",
      "recall : 0.8125 - precision : 0.7222222222222222 - accuracy : 0.7014925373134329\n",
      "MLPC:\n",
      "confusion matrix: \n",
      " [[34 20]\n",
      " [14 66]]\n",
      "recall : 0.825 - precision : 0.7674418604651163 - accuracy : 0.746268656716418\n",
      "XGBC:\n",
      "confusion matrix: \n",
      " [[19 35]\n",
      " [14 66]]\n",
      "recall : 0.825 - precision : 0.6534653465346535 - accuracy : 0.6343283582089553\n",
      "logreg:\n",
      "confusion matrix: \n",
      " [[31 23]\n",
      " [14 66]]\n",
      "recall : 0.825 - precision : 0.7415730337078652 - accuracy : 0.7238805970149254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "150 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/juj/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/juj/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.61325836        nan 0.61325836        nan 0.61325836\n",
      "        nan 0.61325836        nan 0.616945          nan 0.61878409\n",
      "        nan 0.62798799        nan 0.65653828        nan 0.68505898\n",
      "        nan 0.69057202        nan 0.69149368        nan 0.7007145\n",
      "        nan 0.71084429        nan 0.71084852        nan 0.70531434\n",
      "        nan 0.70439691        nan 0.70347525        nan 0.69978861\n",
      "        nan 0.70530588        nan 0.7025409         nan 0.69793684\n",
      "        nan 0.69978438        nan 0.69702786        nan 0.69794952\n",
      "        nan 0.69518877        nan 0.69518877        nan 0.69426711\n",
      "        nan 0.69518877        nan 0.69518877        nan 0.69518877]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_records = records = evaluator.fitting_pipeline(gs = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}\n",
      "{'C': 0.1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "{'C': 0.1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 1000, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "{'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.01, 'loss': 'log_loss', 'max_depth': 3, 'max_features': 'log2', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 0.1, 'min_samples_split': 0.1, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_iter_no_change': None, 'random_state': None, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "{'C': 0.001, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "for record in evaluator.train_records.keys():\n",
    "    model = evaluator.train_records[record]['model']\n",
    "    evaluator.score_classifier_on_test_set()\n",
    "    print(model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "- prevent user from entering negative values for some stuff + impossible values (attemps > made)\n",
    "- pretty print results in webapp\n",
    "- make app responsive\n",
    "- automate training with clic\n",
    "- feature engineering (PCA)\n",
    "- make notebook pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
